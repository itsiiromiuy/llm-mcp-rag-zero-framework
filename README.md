I'll help you translate the project documentation from Chinese to English. Here's the full translation:

# LLM-MCP-RAG Zero Framework Implementation

Implementation of Large Language Model (LLM) integration with Model Context Protocol (MCP) and Retrieval Augmented Generation (RAG) using native methods, without relying on third-party frameworks.

## Project Goals

- Implement enhanced LLM (Chat + MCP + RAG)
- No dependency on external frameworks (like LangChain, CrewAI, AutoGen, etc.)
- Provide clear code structure and type definitions

## Functional Modules

### MCP (Model Context Protocol)

- Support for multiple MCP servers
- Implementation based on [TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)
- Unified tool calling interface

### RAG (Retrieval Augmented Generation)

- Retrieve relevant knowledge from different sources
- Insert retrieved information into context
- Pass to LLM for answer generation

### Workflow

- Website content: Read website -> Organize information -> Summarize -> Store
- PDF documents: Read PDF -> Organize information -> Summarize -> Store

## Project Structure

```
src/
├── constants.ts       # Constant definitions
├── GeminiChatClient.ts # Google Gemini client
├── index.ts           # Main entry file
├── MCPClient.ts       # MCP client
├── types.ts           # Type definitions
└── utils.ts           # Common utility functions
```

## Installation

1. Clone the repository

```bash
git clone https://github.com/yourusername/llm-mcp-rag-zero-framework.git
cd llm-mcp-rag-zero-framework
```

2. Install dependencies

```bash
npm install
```

3. Install uv (MCP server dependency)

```bash
brew install uv # macOS
# For other systems, please refer to: https://docs.astral.sh/uv/getting-started/installation/
```

4. Create .env file

```bash
touch .env
```

Add the following content to the .env file:

```
GOOGLE_API_KEY=your_google_api_key_here
```

## Usage

1. Build the project

```bash
npm run build
```

2. Run the project

```bash
npm start
```

Or use development mode:

```bash
npm run dev
```

3. Test MCP server

```bash
npx @modelcontextprotocol/inspector uvx mcp-server-fetch
```

## Cursor IDE Configuration

This project includes configuration files for Cursor IDE:

1. `.cursorignore` - Defines files and directories that Cursor should ignore
2. `.cursor/settings.json` - Cursor IDE configuration settings

### Cursor Ignore Rules

The `.cursorignore` file uses a pattern syntax similar to `.gitignore`, specifying the following ignore rules:

- Dependency directories (node_modules/, dist/)
- Build outputs (build/, out/)
- Environment files (.env, etc.)
- Logs and cache files
- Files generated by operating systems and editors

To modify ignore rules, please edit the `.cursorignore` file.

## API References

### LLM

- Google Gemini API: https://ai.google.dev/gemini-api/docs/text-generation

### MCP

- TypeScript SDK: https://github.com/modelcontextprotocol/typescript-sdk
- MCP Architecture: https://modelcontextprotocol.io/docs/concepts/architecture
- Quick Start: https://modelcontextprotocol.io/quickstart/client
- Fetch Server: https://github.com/modelcontextprotocol/servers/tree/main/src/fetch
- File System Server: https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem

### RAG Resources

- [Retrieval Augmented Generation (RAG) Overview](https://www.youtube.com/watch?v=1ifymr7SiH8)
- Loader Examples: [langchain](https://python.langchain.com/docs/integrations/document_loaders/)
- JSON Test API: [jsonplaceholder](https://jsonplaceholder.typicode.com/)
 
 
## Reference Links

- [Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)